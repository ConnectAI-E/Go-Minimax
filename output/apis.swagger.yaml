swagger: "2.0"
info:
  title: minimax/text/v1/chat.proto
  version: version not set
tags:
  - name: MinimaxService
consumes:
  - application/json
produces:
  - application/json
paths:
  /v1/text/chatcompletion:
    post:
      operationId: MinimaxService_ChatCompletions
      responses:
        "200":
          description: A successful response.
          schema:
            $ref: '#/definitions/v1ChatCompletionsResponse'
        default:
          description: An unexpected error response.
          schema:
            $ref: '#/definitions/rpcStatus'
      parameters:
        - name: body
          in: body
          required: true
          schema:
            $ref: '#/definitions/v1ChatCompletionsRequest'
      tags:
        - MinimaxService
  /v1/text/chatcompletion-stream:
    post:
      operationId: MinimaxService_ChatCompletionStream
      responses:
        "200":
          description: A successful response.(streaming responses)
          schema:
            type: object
            properties:
              result:
                $ref: '#/definitions/v1ChatCompletionsResponse'
              error:
                $ref: '#/definitions/rpcStatus'
            title: Stream result of v1ChatCompletionsResponse
        default:
          description: An unexpected error response.
          schema:
            $ref: '#/definitions/rpcStatus'
      parameters:
        - name: body
          in: body
          required: true
          schema:
            $ref: '#/definitions/v1ChatCompletionsRequest'
      tags:
        - MinimaxService
definitions:
  protobufAny:
    type: object
    properties:
      '@type':
        type: string
    additionalProperties: {}
  rpcStatus:
    type: object
    properties:
      code:
        type: integer
        format: int32
      message:
        type: string
      details:
        type: array
        items:
          type: object
          $ref: '#/definitions/protobufAny'
  v1BaseResponse:
    type: object
    properties:
      statusCode:
        type: string
        format: int64
        title: |-
          状态码
               1000，未知错误
               1001，超时
               1002，触发限流
               1004，鉴权失败
               1008，余额不足
               1013，服务内部错误
               1027，输出内容严重违规
               2013，输入格式信息不正常
      statusMsg:
        type: string
        title: 错误详情
  v1ChatCompletionsRequest:
    type: object
    properties:
      model:
        type: string
        title: |-
          目前只能取以下一个值
          abab5-chat
      withEmotion:
        type: boolean
        title: 否 对回复添加情绪预测。注意，当with_emotion=true，且请求上下文（输入和输出文本）长时，请求会显著变慢，达到数秒。
      stream:
        type: boolean
        title: "否 \t是否以流式接口的形式返回数据，默认false。"
      useStandardSse:
        type: boolean
        title: 是否通过流式分批返回结果。如果设置为true，结果分批返回，以一个换行为分割符；若希望使用标准SSE响应格式，可以设置use_standard_sse参数为true。默认false
      beamWidth:
        type: integer
        format: int32
        title: 生成多少个结果；不设置默认为1，最大不超过4。 由于beam_width生成多个结果，会消耗更多token。 默认1
      prompt:
        type: string
        title: 对话背景、人物或功能设定 长度上限为4096个token，不可为空
      roleMeta:
        $ref: '#/definitions/v1RoleMeta'
        title: '对话上下文信息。说明："user_name": "我", "bot_name": "专家"'
      messages:
        type: array
        items:
          type: object
          $ref: '#/definitions/v1Message'
        title: |-
          是 	聊天上下文信息。说明：
          （1）messages成员不能为空，1个成员表示单轮对话，多个成员表示多轮对话。
          （2）最后一个message为当前请求的信息，前面的message为历史对话信息。
          （3）必须为奇数个成员，成员中message的role必须依次为user、assistant。
          （4）最后一个message的content长度（即此轮对话的问题）不能超过2000个字符；如果messages中content总长度大于2000字符，系统会依次遗忘最早的历史会话，直到content的总长度不超过2000个字符。
      temperature:
        type: number
        format: float
      topP:
        type: number
        format: float
      skipInfoMask:
        type: boolean
        title: 对输出中易涉及隐私问题的文本信息进行脱敏，目前包括但不限于邮箱、域名、链接、证件号、家庭住址等，默认false，即开启脱敏 默认false
  v1ChatCompletionsResponse:
    type: object
    properties:
      created:
        type: string
        format: int64
        title: 请求发起时间
      model:
        type: string
        title: 请求指定的模型
      reply:
        type: string
        title: 推荐的最好结果
      choices:
        type: array
        items:
          type: object
          $ref: '#/definitions/v1Choice'
        title: 所有结果
      usage:
        $ref: '#/definitions/v1Usage'
        title: tokens数使用情况
      inputSensitive:
        type: boolean
        title: 输入命中敏感词
      outputSensitive:
        type: boolean
        title: 输出命中敏感词
      baseResp:
        $ref: '#/definitions/v1BaseResponse'
        title: 错误状态码和详情
  v1Choice:
    type: object
    properties:
      text:
        type: string
        title: 文本结果
      index:
        type: string
        format: int64
        title: 排名
      logprobes:
        type: string
        format: int64
        title: 分数
      finishReason:
        type: string
        title: |-
          结束原因，枚举值
          stop：API返回了模型生成的完整结果
          length：模型生成结果超过tokens_to_generate的长度，内容被截断
      emotion:
        type: string
        title: |-
          回复文本情绪预测
          取值为以下八者其一 伤心 尴尬 开心 惊讶 愤怒 慌张 疑惑 自然
      delta:
        type: string
        title: 当request.stream为true，处于流式模式下，回复文本通过delta给出
  v1Message:
    type: object
    properties:
      senderType:
        type: string
        title: |-
          当前支持以下：
          USER: 表示用户
          BOT: 表示对话助手
      text:
        type: string
        title: 对话内容，不能为空。
  v1RoleMeta:
    type: object
    properties:
      userName:
        type: string
      botName:
        type: string
  v1Usage:
    type: object
    properties:
      totalTokens:
        type: string
        format: int64
        title: |-
          消耗tokens总数，包括输入和输出；具体计算方式为输入tokens + 最大输出tokens x beam_width。
          假设beam_width为2，输入tokens为100，输出结果分别为20tokens和30tokens，最终消耗160tokens
